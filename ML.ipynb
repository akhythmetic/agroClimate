
import pandas as pd #manipuler les données
import matplotlib.pyplot as plt #créer des visualisations
import seaborn as sns #créer des visualisations
from sklearn.model_selection import train_test_split #entraîner et évaluer un modèle
from sklearn.metrics import r2_score, mean_absolute_error
from xgboost import XGBRegressor #pour la régression

#  Charger les données
file_path = "climate_change_impact_on_agriculture_2024.csv"  
df = pd.read_csv(file_path)

#  Convertir les variables catégorielles en numériques(Nord sud etc ..pour que le modèle puisse les traiter)
df_encoded = df.copy()
for col in df.select_dtypes(include=["object"]).columns:
    df_encoded[col] = df_encoded[col].astype("category").cat.codes

#  Définition de la variable cible (rendement des cultures)
y = df_encoded["Crop_Yield_MT_per_HA"]

# Sélection initiale des variables explicatives (on enlève la cible pour la prédiction)
X = df_encoded.drop(columns=["Crop_Yield_MT_per_HA"])

#  Séparation en jeu d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#  Entraîner un XGBoost simple pour voir les variables importantes (Identifier les variables importantes)
xgb_test = XGBRegressor(n_estimators=50, random_state=42)
xgb_test.fit(X_train, y_train)

#  Sélection des 3 meilleures variables 
feature_importance = pd.Series(xgb_test.feature_importances_, index=X_train.columns)
top_features = feature_importance.nlargest(3).index.tolist()
print(f"Variables sélectionnées : {top_features}")

# Réentraîner avec ces 3 variables (un dataset qu'avec ces 3 variables)
X_best = df_encoded[top_features]
X_train_best, X_test_best, y_train_best, y_test_best = train_test_split(X_best, y, test_size=0.2, random_state=42)

#  Modèle XGBoost optimisé (Entraîner un modèle XGBoost amélioré, uniquement avec les variables importantes)
xgb_model = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=4, random_state=42)
xgb_model.fit(X_train_best, y_train_best)

#  Prédictions
y_pred_best = xgb_model.predict(X_test_best)

#  Évaluation du modèle
r2_best = r2_score(y_test_best, y_pred_best)
mae_best = mean_absolute_error(y_test_best, y_pred_best) #erreur entre valeurs réelles et prédites
print(f"Score R² : {r2_best:.2f}, MAE : {mae_best:.2f}")

# Visualisation des résultats
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test_best, y=y_pred_best, alpha=0.6, label="Prédictions XGBoost")
plt.plot([y_test_best.min(), y_test_best.max()], [y_test_best.min(), y_test_best.max()], 'r--', label="Référence parfaite")

#  Titres et légendes
plt.xlabel("Valeurs Réelles du Rendement (MT/HA)")
plt.ylabel("Valeurs Prédites du Rendement (MT/HA)")
plt.title(f"Prédiction du Rendement avec XGBoost\n(R² = {r2_best:.2f}, MAE = {mae_best:.2f})")
plt.legend()
plt.grid()

#  Affichage du graphique
plt.show()


print(f"Nombre de points affichés : {len(y_test_best)}")

